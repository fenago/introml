{"metadata":{"orig_nbformat":4,"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"#Import your Libraries\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport sklearn.metrics as metrics\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"2dac3d66-b2d4-49df-8540-82d05eeff307"},{"cell_type":"code","source":"# %%timeit -n 1\n# Load your data  -- start with CreditScoring.csv... then Life Expectancy - and then choose another one\ndf = pd.read_csv('./CreditScoring.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"c21f8a1a-a9d5-4277-868f-bef4e51785a9"},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"823b6b3a-c279-4b3e-9b75-75ab01f8ed0b"},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"dfdc07fd-82d6-411c-bf4e-4012315538e1"},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"4f5bc2f4-a159-4a24-b02d-cf234b7daefa"},{"cell_type":"code","source":"df.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"960afc07-cb45-4851-aa9b-6a564d943273"},{"cell_type":"code","source":"df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"17fa6add-bdac-4d33-8b96-e102f3d13bc5"},{"cell_type":"code","source":"# Basic Data Cleaning\ndf.columns = df.columns.str.lower().str.replace(' ', '_') # A\n \nstring_columns = list(df.dtypes[df.dtypes == 'object'].index) # B\n \nfor col in string_columns:\n    df[col] = df[col].str.lower().str.replace(' ', '_') # C","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"03c95958-f524-486f-84dd-62eccffe2985"},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"5694febc-4570-4e82-a40a-4e347e468eb6"},{"cell_type":"code","source":"df.head().T","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"cfd18cea-dbe5-4ac0-864c-922704a8f46a"},{"cell_type":"code","source":"# Categorical Values will be encoded with the Dictionary Vectorizor\n# Numerical Values: At a minimum - clean the missing values and ","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"d7b21bde-5ba4-4806-bbb1-4c750abd7e16"},{"cell_type":"code","source":"# For instance - in the CreditScoring dataset - there are numerous 99999999 that need to be replaced\n# Obviously don't run this with your dataset\nfor c in ['income', 'assets', 'debt']:\n    df[c] = df[c].replace(to_replace=99999999, value=np.nan)\ndf = df[df.status != 'unk']   # Also make sure to treat the target variable","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"2cbc6fd3-13ac-4947-b727-b15f7cd74520"},{"cell_type":"code","source":"# Replace with your target variable --- df.YOUR_TARGET_VARIABLE  \n# Also replace your X label\nplt.figure(figsize=(6, 4))\n\nsns.histplot(df.status, bins=40, color='black', alpha=1)\nplt.ylabel('Frequency')\nplt.xlabel('status')\nplt.title('Distribution of prices')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"227d8604-3160-4070-a1b8-b7c2e71ce771"},{"cell_type":"code","source":"# Check for nulls --- you do NOT want nulls when you train\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"4ad70d6b-e458-4bb7-be22-f550a07aed9f"},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"a8a3347d-5141-4b92-bb07-3dc2dbc1bf3a"},{"cell_type":"code","source":"#delete columns --- this may or may NOT be needed.  As before - skip if you don't need it\n# You will encounter times where you will want to delete columns.  This is how you do that.\n# df = df.drop(['x5_latitude', 'x6_longitude', 'x1_transaction_date'], axis=1)\n# df","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"2871e2ab-8677-43b4-bba1-36fe991438ab"},{"cell_type":"code","source":"'''\n# Split the data into test, train, validation sets... 60/20/20\nfrom sklearn.model_selection import train_test_split\n# This gives the 80/20 train test split\ndf_train_full, df_test = train_test_split(df, test_size=0.2, random_state=11)\n# This splits df_train_full again so it is 60/20/20\ndf_train, df_val = train_test_split(df_train_full, test_size=0.25, random_state=11)\nlen(df_train), len(df_val), len(df_test)\n# Replace nulls with 0's - these are pandas dataframes\ndf_train = df_train.fillna(0)\ndf_val = df_val.fillna(0)\ndf_test = df_test.fillna(0)\nlen(df_train),len(df_val),len(df_test)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"fe1b5783-3f32-4440-81b7-1ae401f4ef09"},{"cell_type":"code","source":"# Split the data into test, train, validation sets... 80/20\nfrom sklearn.model_selection import train_test_split\n# This gives the 80/20 train test split\ndf_train_full, df_test = train_test_split(df, test_size=0.2, random_state=11)\n\nlen(df_train_full), len(df_test)\n# Replace nulls with 0's - these are pandas dataframes\ndf_train_full = df_train_full.fillna(0)\n\ndf_test = df_test.fillna(0)\nlen(df_train_full),len(df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"79babb7b-c583-4831-b555-54e68361b295"},{"cell_type":"code","source":"#Split the y out into train/test/splits... these are numpy ndarrays ... msrp is your target variables\n# Replace with your target variable!!!  \ny_train = (df_train_full.status).values\ny_test = (df_test.status).values\ndel df_train_full['status']\ndel df_test['status']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"033173c4-f018-4f63-b21b-f04209d392f7"},{"cell_type":"code","source":"len(y_train),len(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"cb9de144-603a-4450-892a-6d724878ed1a"},{"cell_type":"code","source":"# Convert these data frames into a LIST of DICTIONARIES (each element in the list is a dictionary (the record))\ndict_train = df_train_full.to_dict(orient='records')\ndict_test = df_test.to_dict(orient='records')","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"65eccd7c-38b2-4c32-9408-1c3e4eeb78e9"},{"cell_type":"code","source":"# Convert the LIST OF DICTIONARIES into a Feature Matrix (does all of the encoding)\nfrom sklearn.feature_extraction import DictVectorizer\n \ndv = DictVectorizer(sparse=False)\n \nX_train = dv.fit_transform(dict_train)\nX_test = dv.transform(dict_test)\nfeatures = dv.get_feature_names_out()  #Features as they exist in the Vectorized Dictionary (this is an ndarray)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"8430e24e-0e56-4b06-8b2b-465762403e19"},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"e78f7c8e-e9f3-4a18-8d3c-b64873597b52"},{"cell_type":"code","source":"# Compare Algorithms\nfrom sklearn.metrics import roc_auc_score\nfrom time import time\nfrom sklearn.metrics import explained_variance_score,mean_absolute_error,r2_score\nfrom pandas import read_csv\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear')))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC(gamma='auto')))\n# evaluate each model in turn\nresults = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n    start = time()\n    kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n    model.fit(X_train, y_train)\n    train_time = time() - start\n    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    predict_time = time()-start \n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    #y_pred = model.predict_proba(X_train)[:, 1]\n    #auc = roc_auc_score(y_train, y_pred)\n    print(msg)\n    print(\"Score for each of the 10 K-fold tests: \",cv_results)\n    print(model)\n    print(\"\\tTraining time: %0.3fs\" % train_time)\n    print(\"\\tPrediction time: %0.3fs\" % predict_time)\n    #y_pred = model.predict(X_test)\n    #print(\"\\tExplained variance:\", explained_variance_score(y_test, y_pred))\n    print()\n    \n    \n    \n# boxplot algorithm comparison\nfig = pyplot.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\npyplot.boxplot(results)\nax.set_xticklabels(names)\npyplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"3c6ec7d7-b95f-496a-9b4b-82ddabb0b1ab"},{"cell_type":"markdown","source":"# Once you identify a single model or two - begin to investigate","metadata":{},"id":"a1e2fe12-ea3d-4e2d-965b-8e4d1c0dd661"},{"cell_type":"code","source":"# %%timeit -n 1\n# if you uncomment %%timeit it will not put lr into memory\n# Let's assume that the decision tree is the one we want to explore\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"6d025def-452c-4def-807f-1da7523f0b60"},{"cell_type":"code","source":"dt.get_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"855abbd3-905c-4c96-93d1-c08ab4c495a9"},{"cell_type":"code","source":"type(X_train)\ntype(dv.get_feature_names_out())\ntype(dt.feature_importances_)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"4f6b5c2e-b5ea-41de-9943-da13c9b54e02"},{"cell_type":"code","source":"# These are the model properties.  You can call all of these\ndef get_properties(model):   \n  return [i for i in model.__dict__ if i.endswith('_')] \nget_properties(dt)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"b77b032f-0766-48e7-ac77-1ba688e3ffc2"},{"cell_type":"code","source":"from sklearn.tree import export_text \n \ntree_text = export_text(dt, feature_names=dv.feature_names_) \nprint(tree_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"ad10a5b7-e27c-4df3-8fce-118889329a33"},{"cell_type":"code","source":"feature_names=dv.feature_names_\n# Evaluate the coefficients to learn what the model thinks is important in the predictions.\nfor i,j in zip(feature_names, dt.feature_importances_): print('%.3f' % j, i)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"a70eb705-485e-4e11-84f6-357949838a1a"},{"cell_type":"code","source":"from sklearn.metrics import f1_score\ny_pred = dt.predict_proba(X_test)[:, 1]\ny_pred = y_pred.astype('int')\nf1_score(y_test, y_pred, average=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"82acda9d-b8a1-4517-8592-d7def874041f"},{"cell_type":"code","source":"y_pred.dtype","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"c982d83f-a5c9-4e71-a57f-1424de4f7640"},{"cell_type":"code","source":"# https://github.com/sepandhaghighi/pycm\n!pip install pycm\nfrom pycm import ConfusionMatrix\ncm = ConfusionMatrix(actual_vector=y_test,predict_vector=y_pred)\n# cm = ConfusionMatrix(y_actu, y_pred, classes=[1,0,4])\nprint(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"6fe5b7a3-0dd0-4848-94d4-75e42ce45518"},{"cell_type":"code","source":"type(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"cc78cca8-2d73-42ef-93e5-687f9f7299f3"},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix\n\ncnf_matrix = confusion_matrix(y_test, y_pred)\nprint(cnf_matrix)\n#[[1 1 3]\n# [3 2 2]\n# [1 3 1]]\n\nFP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \nFN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\nTP = np.diag(cnf_matrix)\nTN = cnf_matrix.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\n# print(FP)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\n# Sensitivity, hit rate, recall, or true positive rate\nTPR = TP/((TP+FN)+.01)\n# Specificity or true negative rate\nTNR = TN/((TN+FP)+.01)\n# Precision or positive predictive value\nPPV = TP/((TP+FP)+.01)\n# Negative predictive value\nNPV = TN/((TN+FN)+.01)\n# Fall out or false positive rate\nFPR = FP/((FP+TN)+.01)\n# False negative rate\nFNR = FN/((TP+FN)+.01)\n# False discovery rate\nFDR = FP/((TP+FP)+.01)\n# Overall accuracy\nACC = (TP+TN)/(TP+FP+FN+TN)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"b409e76c-e2b0-46b4-ba44-d6bbd475f2e6"},{"cell_type":"markdown","source":"The AUC-ROC curve is only for binary classification problems. But we can extend it to multiclass classification problems by using the One vs All technique(calculating auc-roc curve considering each label at a time and all the other can be grouped as one  label)","metadata":{},"id":"5c113874-33ea-46fa-ba6b-bb93d6741097"},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(\"For classification report:\")\nprint(classification_report(y_test , y_pred))\n\nfrom sklearn.metrics import confusion_matrix\nprint(\"For confusion matrix\")\nprint(confusion_matrix(y_test , y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"9c4b11c1-bb50-4238-a247-95a9495e948c"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"78b66286-d96c-45c9-94f5-6edcbb7e4cd9"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"4147b82b-70c5-413d-9473-b5ddc453450a"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"5349237f-855b-4790-b698-365cfd45cdaf"},{"cell_type":"code","source":"pred_y = dt.predict(X_test)\nprint(\"The first 10 prediction {}\".format(pred_y[:10].round(0)))\nprint(\"The real first 10 labels {}\".format(y_test[:10]))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"4a0ca23f-81cd-4f0a-b815-66ab6d56dafd"},{"cell_type":"code","source":"type(df_train_full.head(1))","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"6458b9b4-53f5-4325-8cc8-e316fb20eae0"},{"cell_type":"code","source":"# Use double brackets around the iloc to force it to return a pandas dataframe and not a series\n# Then you can convert any record into a dictionary\ndf_train_full.iloc[[21]]","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"6cfd0fbc-b397-4c86-9be0-4d5b105c7a04"},{"cell_type":"code","source":"# How to convert any pandas row into a dictionary... needed for predictions\ndf_train_full.iloc[[213]].to_dict('records')[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"0b519a52-11f8-4d03-9cb2-fee16a79acbf"},{"cell_type":"code","source":"# How to convert any pandas row into a dictionary... needed for predictions\ndf_train_full.head(21).to_dict('records')[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"78bc6352-6bab-4356-9e6e-07c1a977a06f"},{"cell_type":"code","source":"#car = df_train.head(1).to_dict('records')[0]\nitem = df_train_full.iloc[[213]].to_dict('records')[0]\nactual = y_train[[213]]","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"8f58aa87-c643-4a94-b0ab-c0582ee4e18d"},{"cell_type":"code","source":"# The item to be predicted is passed in.  \ndef model_prediction(item, dv, model):\n    X = dv.transform([item])\n    y_pred = model.predict(X)\n    return y_pred[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"0b8da488-76d2-4c2e-88b4-59f0390517e4"},{"cell_type":"code","source":"model_prediction(item,dv,dt)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"25ee6832-7b4b-40f1-9f02-46f611d87968"},{"cell_type":"code","source":"actual","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"a2dbd283-4485-44e5-aa81-fdc0c0ebb813"},{"cell_type":"code","source":"dt.get_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"940c8c4e-d164-4da0-8287-630f7306b78a"},{"cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{},"id":"a3376d80-ebf1-4a3b-9570-f01c2bb16cc8"},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nparams = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\ngrid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=3)\ngrid_search_cv.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"976b78b1-f559-48bb-b0fc-2ace1b82088f"},{"cell_type":"code","source":"grid_search_cv.best_estimator_    # this will output the best values for the hyperparameters","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"633aa3d9-1e39-4c1c-b889-1684f99e9825"},{"cell_type":"code","source":"from sklearn.tree import export_graphviz\nexport_graphviz( \n grid_search_cv.best_estimator_,\n out_file=('tree.dot'),\n feature_names=None,\n class_names=None,\n filled=True,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"bd4ea648-fadd-4604-92e0-c5d39657eb9c"},{"cell_type":"code","source":"!pip install pydot\nimport pydot\n\n(graph,) = pydot.graph_from_dot_file('tree.dot')\ngraph.write_png('tree.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"4b1d5356-f985-4b12-8982-b8107596c1b7"},{"cell_type":"code","source":"# You can change the params by editing the output of this and repeating the above steps.\ndt.get_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"44b575ad-7e8b-4486-98f3-4c70510aa742"},{"cell_type":"code","source":"#Many parameters will take a very long time to load\nparam = { 'max_depth': [2,3,5,20,40], \n         'max_leaf_nodes': [2,20,200]}","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"f7881392-37cd-405b-8f80-3282f763a90e"},{"cell_type":"code","source":"metrics.SCORERS.keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"c46cb5ba-a070-47f1-9e17-7e61b44d1054"},{"cell_type":"code","source":"from sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import GridSearchCV\ncv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n# define search\nsearch = GridSearchCV(dt, param, scoring='accuracy', n_jobs=-1, cv=cv)\n# execute search\nresult = search.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"91bd0b8f-8fd4-4e9a-9823-d6f531790d63"},{"cell_type":"code","source":"# summarize result\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"46caaf03-88e3-4434-9ac2-0ce804f8e020"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"303e98c0-40ed-42c3-9c74-df96f0747223"}]}