{"metadata":{"orig_nbformat":4,"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"#Import your Libraries\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nimport sklearn.metrics as metrics\n%matplotlib inline","metadata":{"trusted":true},"execution_count":1,"outputs":[],"id":"2dac3d66-b2d4-49df-8540-82d05eeff307"},{"cell_type":"code","source":"# %%timeit -n 1\n# Load your data  -- start with CreditScoring.csv... then Life Expectancy - and then anyone you choose\n# Replace with your dataset... for instance - if it is on github -use:  https://raw.githubusercontent.com/fenago/introml/main/Life%20Expectancy%20Data.csv\ndf = pd.read_csv('./CreditScoring.csv')","metadata":{"trusted":true},"execution_count":2,"outputs":[],"id":"c21f8a1a-a9d5-4277-868f-bef4e51785a9"},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"4455"},"metadata":{}}],"id":"823b6b3a-c279-4b3e-9b75-75ab01f8ed0b"},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"            Status    Seniority         Home         Time          Age  \\\ncount  4455.000000  4455.000000  4455.000000  4455.000000  4455.000000   \nmean      1.281257     7.987205     2.657015    46.441751    37.077666   \nstd       0.450162     8.173444     1.610467    14.655225    10.984856   \nmin       0.000000     0.000000     0.000000     6.000000    18.000000   \n25%       1.000000     2.000000     2.000000    36.000000    28.000000   \n50%       1.000000     5.000000     2.000000    48.000000    36.000000   \n75%       2.000000    12.000000     4.000000    60.000000    45.000000   \nmax       2.000000    48.000000     6.000000    72.000000    68.000000   \n\n           Marital      Records          Job     Expenses        Income  \\\ncount  4455.000000  4455.000000  4455.000000  4455.000000  4.455000e+03   \nmean      1.879012     1.173513     1.675870    55.568799  7.633170e+05   \nstd       0.643748     0.378733     0.954035    19.515878  8.703625e+06   \nmin       0.000000     1.000000     0.000000    35.000000  0.000000e+00   \n25%       2.000000     1.000000     1.000000    35.000000  8.000000e+01   \n50%       2.000000     1.000000     1.000000    51.000000  1.200000e+02   \n75%       2.000000     1.000000     3.000000    72.000000  1.660000e+02   \nmax       5.000000     2.000000     4.000000   180.000000  1.000000e+08   \n\n             Assets          Debt       Amount         Price  \ncount  4.455000e+03  4.455000e+03  4455.000000   4455.000000  \nmean   1.060341e+06  4.043820e+05  1039.021773   1462.875645  \nstd    1.021757e+07  6.344253e+06   474.543007    628.089913  \nmin    0.000000e+00  0.000000e+00   100.000000    105.000000  \n25%    0.000000e+00  0.000000e+00   700.000000   1117.500000  \n50%    3.500000e+03  0.000000e+00  1000.000000   1400.000000  \n75%    6.000000e+03  0.000000e+00  1300.000000   1692.000000  \nmax    1.000000e+08  1.000000e+08  5000.000000  11140.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Status</th>\n      <th>Seniority</th>\n      <th>Home</th>\n      <th>Time</th>\n      <th>Age</th>\n      <th>Marital</th>\n      <th>Records</th>\n      <th>Job</th>\n      <th>Expenses</th>\n      <th>Income</th>\n      <th>Assets</th>\n      <th>Debt</th>\n      <th>Amount</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4455.000000</td>\n      <td>4455.000000</td>\n      <td>4455.000000</td>\n      <td>4455.000000</td>\n      <td>4455.000000</td>\n      <td>4455.000000</td>\n      <td>4455.000000</td>\n      <td>4455.000000</td>\n      <td>4455.000000</td>\n      <td>4.455000e+03</td>\n      <td>4.455000e+03</td>\n      <td>4.455000e+03</td>\n      <td>4455.000000</td>\n      <td>4455.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.281257</td>\n      <td>7.987205</td>\n      <td>2.657015</td>\n      <td>46.441751</td>\n      <td>37.077666</td>\n      <td>1.879012</td>\n      <td>1.173513</td>\n      <td>1.675870</td>\n      <td>55.568799</td>\n      <td>7.633170e+05</td>\n      <td>1.060341e+06</td>\n      <td>4.043820e+05</td>\n      <td>1039.021773</td>\n      <td>1462.875645</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.450162</td>\n      <td>8.173444</td>\n      <td>1.610467</td>\n      <td>14.655225</td>\n      <td>10.984856</td>\n      <td>0.643748</td>\n      <td>0.378733</td>\n      <td>0.954035</td>\n      <td>19.515878</td>\n      <td>8.703625e+06</td>\n      <td>1.021757e+07</td>\n      <td>6.344253e+06</td>\n      <td>474.543007</td>\n      <td>628.089913</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>18.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>35.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>100.000000</td>\n      <td>105.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>36.000000</td>\n      <td>28.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>35.000000</td>\n      <td>8.000000e+01</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>700.000000</td>\n      <td>1117.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>5.000000</td>\n      <td>2.000000</td>\n      <td>48.000000</td>\n      <td>36.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>51.000000</td>\n      <td>1.200000e+02</td>\n      <td>3.500000e+03</td>\n      <td>0.000000e+00</td>\n      <td>1000.000000</td>\n      <td>1400.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.000000</td>\n      <td>12.000000</td>\n      <td>4.000000</td>\n      <td>60.000000</td>\n      <td>45.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>72.000000</td>\n      <td>1.660000e+02</td>\n      <td>6.000000e+03</td>\n      <td>0.000000e+00</td>\n      <td>1300.000000</td>\n      <td>1692.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.000000</td>\n      <td>48.000000</td>\n      <td>6.000000</td>\n      <td>72.000000</td>\n      <td>68.000000</td>\n      <td>5.000000</td>\n      <td>2.000000</td>\n      <td>4.000000</td>\n      <td>180.000000</td>\n      <td>1.000000e+08</td>\n      <td>1.000000e+08</td>\n      <td>1.000000e+08</td>\n      <td>5000.000000</td>\n      <td>11140.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"id":"dfdc07fd-82d6-411c-bf4e-4012315538e1"},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(4455, 14)"},"metadata":{}}],"id":"4f5bc2f4-a159-4a24-b02d-cf234b7daefa"},{"cell_type":"code","source":"df.nunique()","metadata":{"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Status          3\nSeniority      47\nHome            7\nTime           11\nAge            50\nMarital         6\nRecords         2\nJob             5\nExpenses       94\nIncome        353\nAssets        160\nDebt          183\nAmount        285\nPrice        1419\ndtype: int64"},"metadata":{}}],"id":"960afc07-cb45-4851-aa9b-6a564d943273"},{"cell_type":"code","source":"df.corr()","metadata":{"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"             Status  Seniority      Home      Time       Age   Marital  \\\nStatus     1.000000  -0.260312  0.051025  0.099935 -0.094498  0.010535   \nSeniority -0.260312   1.000000 -0.145878 -0.021320  0.505787  0.163433   \nHome       0.051025  -0.145878  1.000000 -0.020880 -0.270784 -0.260712   \nTime       0.099935  -0.021320 -0.020880  1.000000 -0.051966  0.049978   \nAge       -0.094498   0.505787 -0.270784 -0.051966  1.000000  0.325652   \nMarital    0.010535   0.163433 -0.260712  0.049978  0.325652  1.000000   \nRecords    0.278638  -0.015674 -0.013205  0.028094  0.060171  0.082440   \nJob        0.152722  -0.109339 -0.032042 -0.138454  0.179447  0.034105   \nExpenses   0.029499   0.125798 -0.334092 -0.001059  0.248254  0.210315   \nIncome     0.059807  -0.034262 -0.022968 -0.020246  0.010653  0.004463   \nAssets     0.032989   0.026380 -0.020389 -0.039491  0.053084 -0.007824   \nDebt       0.062401   0.005725 -0.043584 -0.051170  0.015971  0.000985   \nAmount     0.153771  -0.007859 -0.019560  0.431050  0.028907  0.054130   \nPrice      0.010297   0.040922 -0.026542  0.129796  0.048739  0.062537   \n\n            Records       Job  Expenses    Income    Assets      Debt  \\\nStatus     0.278638  0.152722  0.029499  0.059807  0.032989  0.062401   \nSeniority -0.015674 -0.109339  0.125798 -0.034262  0.026380  0.005725   \nHome      -0.013205 -0.032042 -0.334092 -0.022968 -0.020389 -0.043584   \nTime       0.028094 -0.138454 -0.001059 -0.020246 -0.039491 -0.051170   \nAge        0.060171  0.179447  0.248254  0.010653  0.053084  0.015971   \nMarital    0.082440  0.034105  0.210315  0.004463 -0.007824  0.000985   \nRecords    1.000000  0.033898  0.057329  0.034741  0.004926  0.008197   \nJob        0.033898  1.000000  0.024170  0.102801  0.049138  0.029067   \nExpenses   0.057329  0.024170  1.000000  0.010664 -0.023255 -0.018899   \nIncome     0.034741  0.102801  0.010664  1.000000  0.092042  0.116399   \nAssets     0.004926  0.049138 -0.023255  0.092042  1.000000  0.616823   \nDebt       0.008197  0.029067 -0.018899  0.116399  0.616823  1.000000   \nAmount     0.110349  0.055833  0.048958  0.019659  0.014568  0.056259   \nPrice      0.085143  0.056497  0.040162  0.023088  0.029690  0.066406   \n\n             Amount     Price  \nStatus     0.153771  0.010297  \nSeniority -0.007859  0.040922  \nHome      -0.019560 -0.026542  \nTime       0.431050  0.129796  \nAge        0.028907  0.048739  \nMarital    0.054130  0.062537  \nRecords    0.110349  0.085143  \nJob        0.055833  0.056497  \nExpenses   0.048958  0.040162  \nIncome     0.019659  0.023088  \nAssets     0.014568  0.029690  \nDebt       0.056259  0.066406  \nAmount     1.000000  0.725040  \nPrice      0.725040  1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Status</th>\n      <th>Seniority</th>\n      <th>Home</th>\n      <th>Time</th>\n      <th>Age</th>\n      <th>Marital</th>\n      <th>Records</th>\n      <th>Job</th>\n      <th>Expenses</th>\n      <th>Income</th>\n      <th>Assets</th>\n      <th>Debt</th>\n      <th>Amount</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Status</th>\n      <td>1.000000</td>\n      <td>-0.260312</td>\n      <td>0.051025</td>\n      <td>0.099935</td>\n      <td>-0.094498</td>\n      <td>0.010535</td>\n      <td>0.278638</td>\n      <td>0.152722</td>\n      <td>0.029499</td>\n      <td>0.059807</td>\n      <td>0.032989</td>\n      <td>0.062401</td>\n      <td>0.153771</td>\n      <td>0.010297</td>\n    </tr>\n    <tr>\n      <th>Seniority</th>\n      <td>-0.260312</td>\n      <td>1.000000</td>\n      <td>-0.145878</td>\n      <td>-0.021320</td>\n      <td>0.505787</td>\n      <td>0.163433</td>\n      <td>-0.015674</td>\n      <td>-0.109339</td>\n      <td>0.125798</td>\n      <td>-0.034262</td>\n      <td>0.026380</td>\n      <td>0.005725</td>\n      <td>-0.007859</td>\n      <td>0.040922</td>\n    </tr>\n    <tr>\n      <th>Home</th>\n      <td>0.051025</td>\n      <td>-0.145878</td>\n      <td>1.000000</td>\n      <td>-0.020880</td>\n      <td>-0.270784</td>\n      <td>-0.260712</td>\n      <td>-0.013205</td>\n      <td>-0.032042</td>\n      <td>-0.334092</td>\n      <td>-0.022968</td>\n      <td>-0.020389</td>\n      <td>-0.043584</td>\n      <td>-0.019560</td>\n      <td>-0.026542</td>\n    </tr>\n    <tr>\n      <th>Time</th>\n      <td>0.099935</td>\n      <td>-0.021320</td>\n      <td>-0.020880</td>\n      <td>1.000000</td>\n      <td>-0.051966</td>\n      <td>0.049978</td>\n      <td>0.028094</td>\n      <td>-0.138454</td>\n      <td>-0.001059</td>\n      <td>-0.020246</td>\n      <td>-0.039491</td>\n      <td>-0.051170</td>\n      <td>0.431050</td>\n      <td>0.129796</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>-0.094498</td>\n      <td>0.505787</td>\n      <td>-0.270784</td>\n      <td>-0.051966</td>\n      <td>1.000000</td>\n      <td>0.325652</td>\n      <td>0.060171</td>\n      <td>0.179447</td>\n      <td>0.248254</td>\n      <td>0.010653</td>\n      <td>0.053084</td>\n      <td>0.015971</td>\n      <td>0.028907</td>\n      <td>0.048739</td>\n    </tr>\n    <tr>\n      <th>Marital</th>\n      <td>0.010535</td>\n      <td>0.163433</td>\n      <td>-0.260712</td>\n      <td>0.049978</td>\n      <td>0.325652</td>\n      <td>1.000000</td>\n      <td>0.082440</td>\n      <td>0.034105</td>\n      <td>0.210315</td>\n      <td>0.004463</td>\n      <td>-0.007824</td>\n      <td>0.000985</td>\n      <td>0.054130</td>\n      <td>0.062537</td>\n    </tr>\n    <tr>\n      <th>Records</th>\n      <td>0.278638</td>\n      <td>-0.015674</td>\n      <td>-0.013205</td>\n      <td>0.028094</td>\n      <td>0.060171</td>\n      <td>0.082440</td>\n      <td>1.000000</td>\n      <td>0.033898</td>\n      <td>0.057329</td>\n      <td>0.034741</td>\n      <td>0.004926</td>\n      <td>0.008197</td>\n      <td>0.110349</td>\n      <td>0.085143</td>\n    </tr>\n    <tr>\n      <th>Job</th>\n      <td>0.152722</td>\n      <td>-0.109339</td>\n      <td>-0.032042</td>\n      <td>-0.138454</td>\n      <td>0.179447</td>\n      <td>0.034105</td>\n      <td>0.033898</td>\n      <td>1.000000</td>\n      <td>0.024170</td>\n      <td>0.102801</td>\n      <td>0.049138</td>\n      <td>0.029067</td>\n      <td>0.055833</td>\n      <td>0.056497</td>\n    </tr>\n    <tr>\n      <th>Expenses</th>\n      <td>0.029499</td>\n      <td>0.125798</td>\n      <td>-0.334092</td>\n      <td>-0.001059</td>\n      <td>0.248254</td>\n      <td>0.210315</td>\n      <td>0.057329</td>\n      <td>0.024170</td>\n      <td>1.000000</td>\n      <td>0.010664</td>\n      <td>-0.023255</td>\n      <td>-0.018899</td>\n      <td>0.048958</td>\n      <td>0.040162</td>\n    </tr>\n    <tr>\n      <th>Income</th>\n      <td>0.059807</td>\n      <td>-0.034262</td>\n      <td>-0.022968</td>\n      <td>-0.020246</td>\n      <td>0.010653</td>\n      <td>0.004463</td>\n      <td>0.034741</td>\n      <td>0.102801</td>\n      <td>0.010664</td>\n      <td>1.000000</td>\n      <td>0.092042</td>\n      <td>0.116399</td>\n      <td>0.019659</td>\n      <td>0.023088</td>\n    </tr>\n    <tr>\n      <th>Assets</th>\n      <td>0.032989</td>\n      <td>0.026380</td>\n      <td>-0.020389</td>\n      <td>-0.039491</td>\n      <td>0.053084</td>\n      <td>-0.007824</td>\n      <td>0.004926</td>\n      <td>0.049138</td>\n      <td>-0.023255</td>\n      <td>0.092042</td>\n      <td>1.000000</td>\n      <td>0.616823</td>\n      <td>0.014568</td>\n      <td>0.029690</td>\n    </tr>\n    <tr>\n      <th>Debt</th>\n      <td>0.062401</td>\n      <td>0.005725</td>\n      <td>-0.043584</td>\n      <td>-0.051170</td>\n      <td>0.015971</td>\n      <td>0.000985</td>\n      <td>0.008197</td>\n      <td>0.029067</td>\n      <td>-0.018899</td>\n      <td>0.116399</td>\n      <td>0.616823</td>\n      <td>1.000000</td>\n      <td>0.056259</td>\n      <td>0.066406</td>\n    </tr>\n    <tr>\n      <th>Amount</th>\n      <td>0.153771</td>\n      <td>-0.007859</td>\n      <td>-0.019560</td>\n      <td>0.431050</td>\n      <td>0.028907</td>\n      <td>0.054130</td>\n      <td>0.110349</td>\n      <td>0.055833</td>\n      <td>0.048958</td>\n      <td>0.019659</td>\n      <td>0.014568</td>\n      <td>0.056259</td>\n      <td>1.000000</td>\n      <td>0.725040</td>\n    </tr>\n    <tr>\n      <th>Price</th>\n      <td>0.010297</td>\n      <td>0.040922</td>\n      <td>-0.026542</td>\n      <td>0.129796</td>\n      <td>0.048739</td>\n      <td>0.062537</td>\n      <td>0.085143</td>\n      <td>0.056497</td>\n      <td>0.040162</td>\n      <td>0.023088</td>\n      <td>0.029690</td>\n      <td>0.066406</td>\n      <td>0.725040</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"id":"17fa6add-bdac-4d33-8b96-e102f3d13bc5"},{"cell_type":"code","source":"# Basic Data Cleaning\ndf.columns = df.columns.str.lower().str.replace(' ', '_') # A\n \nstring_columns = list(df.dtypes[df.dtypes == 'object'].index) # B\n \nfor col in string_columns:\n    df[col] = df[col].str.lower().str.replace(' ', '_') # C","metadata":{"trusted":true},"execution_count":8,"outputs":[],"id":"03c95958-f524-486f-84dd-62eccffe2985"},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   status  seniority  home  time  age  marital  records  job  expenses  \\\n0       1          9     1    60   30        2        1    3        73   \n1       1         17     1    60   58        3        1    1        48   \n2       2         10     2    36   46        2        2    3        90   \n3       1          0     1    60   24        1        1    1        63   \n4       1          0     1    36   26        1        1    1        46   \n\n   income  assets  debt  amount  price  \n0     129       0     0     800    846  \n1     131       0     0    1000   1658  \n2     200    3000     0    2000   2985  \n3     182    2500     0     900   1325  \n4     107       0     0     310    910  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>status</th>\n      <th>seniority</th>\n      <th>home</th>\n      <th>time</th>\n      <th>age</th>\n      <th>marital</th>\n      <th>records</th>\n      <th>job</th>\n      <th>expenses</th>\n      <th>income</th>\n      <th>assets</th>\n      <th>debt</th>\n      <th>amount</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>60</td>\n      <td>30</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>73</td>\n      <td>129</td>\n      <td>0</td>\n      <td>0</td>\n      <td>800</td>\n      <td>846</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>17</td>\n      <td>1</td>\n      <td>60</td>\n      <td>58</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>48</td>\n      <td>131</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1000</td>\n      <td>1658</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>10</td>\n      <td>2</td>\n      <td>36</td>\n      <td>46</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>90</td>\n      <td>200</td>\n      <td>3000</td>\n      <td>0</td>\n      <td>2000</td>\n      <td>2985</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>60</td>\n      <td>24</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>63</td>\n      <td>182</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>900</td>\n      <td>1325</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>36</td>\n      <td>26</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>46</td>\n      <td>107</td>\n      <td>0</td>\n      <td>0</td>\n      <td>310</td>\n      <td>910</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"id":"5694febc-4570-4e82-a40a-4e347e468eb6"},{"cell_type":"code","source":"df.head().T","metadata":{"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"             0     1     2     3    4\nstatus       1     1     2     1    1\nseniority    9    17    10     0    0\nhome         1     1     2     1    1\ntime        60    60    36    60   36\nage         30    58    46    24   26\nmarital      2     3     2     1    1\nrecords      1     1     2     1    1\njob          3     1     3     1    1\nexpenses    73    48    90    63   46\nincome     129   131   200   182  107\nassets       0     0  3000  2500    0\ndebt         0     0     0     0    0\namount     800  1000  2000   900  310\nprice      846  1658  2985  1325  910","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>status</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>seniority</th>\n      <td>9</td>\n      <td>17</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>home</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>time</th>\n      <td>60</td>\n      <td>60</td>\n      <td>36</td>\n      <td>60</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>30</td>\n      <td>58</td>\n      <td>46</td>\n      <td>24</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>marital</th>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>records</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>job</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>expenses</th>\n      <td>73</td>\n      <td>48</td>\n      <td>90</td>\n      <td>63</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>income</th>\n      <td>129</td>\n      <td>131</td>\n      <td>200</td>\n      <td>182</td>\n      <td>107</td>\n    </tr>\n    <tr>\n      <th>assets</th>\n      <td>0</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>2500</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>debt</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>amount</th>\n      <td>800</td>\n      <td>1000</td>\n      <td>2000</td>\n      <td>900</td>\n      <td>310</td>\n    </tr>\n    <tr>\n      <th>price</th>\n      <td>846</td>\n      <td>1658</td>\n      <td>2985</td>\n      <td>1325</td>\n      <td>910</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"id":"cfd18cea-dbe5-4ac0-864c-922704a8f46a"},{"cell_type":"code","source":"# Categorical Values will be encoded with the Dictionary Vectorizor\n# Numerical Values: At a minimum - clean the missing values and ","metadata":{"trusted":true},"execution_count":11,"outputs":[],"id":"d7b21bde-5ba4-4806-bbb1-4c750abd7e16"},{"cell_type":"code","source":"# For instance - in the CreditScoring dataset - there are numerous 99999999 that need to be replaced\n# Obviously don't run this with your dataset\nfor c in ['income', 'assets', 'debt']:\n    df[c] = df[c].replace(to_replace=99999999, value=np.nan)\ndf = df[df.status != 'unk']   # Also make sure to treat the target variable","metadata":{"trusted":true},"execution_count":12,"outputs":[],"id":"2cbc6fd3-13ac-4947-b727-b15f7cd74520"},{"cell_type":"code","source":"# Replace with your target variable --- df.YOUR_TARGET_VARIABLE  \n# Also replace your X label\nplt.figure(figsize=(6, 4))\n\nsns.histplot(df.status, bins=40, color='black', alpha=1)\nplt.ylabel('Frequency')\nplt.xlabel('status')\nplt.title('Distribution of prices')\n\nplt.show()","metadata":{"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}],"id":"227d8604-3160-4070-a1b8-b7c2e71ce771"},{"cell_type":"code","source":"# Check for nulls --- you do NOT want nulls when you train\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"status        0\nseniority     0\nhome          0\ntime          0\nage           0\nmarital       0\nrecords       0\njob           0\nexpenses      0\nincome       34\nassets       47\ndebt         18\namount        0\nprice         0\ndtype: int64"},"metadata":{}}],"id":"4ad70d6b-e458-4bb7-be22-f550a07aed9f"},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   status  seniority  home  time  age  marital  records  job  expenses  \\\n0       1          9     1    60   30        2        1    3        73   \n1       1         17     1    60   58        3        1    1        48   \n2       2         10     2    36   46        2        2    3        90   \n3       1          0     1    60   24        1        1    1        63   \n4       1          0     1    36   26        1        1    1        46   \n\n   income  assets  debt  amount  price  \n0   129.0     0.0   0.0     800    846  \n1   131.0     0.0   0.0    1000   1658  \n2   200.0  3000.0   0.0    2000   2985  \n3   182.0  2500.0   0.0     900   1325  \n4   107.0     0.0   0.0     310    910  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>status</th>\n      <th>seniority</th>\n      <th>home</th>\n      <th>time</th>\n      <th>age</th>\n      <th>marital</th>\n      <th>records</th>\n      <th>job</th>\n      <th>expenses</th>\n      <th>income</th>\n      <th>assets</th>\n      <th>debt</th>\n      <th>amount</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>60</td>\n      <td>30</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>73</td>\n      <td>129.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>800</td>\n      <td>846</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>17</td>\n      <td>1</td>\n      <td>60</td>\n      <td>58</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>48</td>\n      <td>131.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1000</td>\n      <td>1658</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>10</td>\n      <td>2</td>\n      <td>36</td>\n      <td>46</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>90</td>\n      <td>200.0</td>\n      <td>3000.0</td>\n      <td>0.0</td>\n      <td>2000</td>\n      <td>2985</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>60</td>\n      <td>24</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>63</td>\n      <td>182.0</td>\n      <td>2500.0</td>\n      <td>0.0</td>\n      <td>900</td>\n      <td>1325</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>36</td>\n      <td>26</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>46</td>\n      <td>107.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>310</td>\n      <td>910</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"id":"a8a3347d-5141-4b92-bb07-3dc2dbc1bf3a"},{"cell_type":"code","source":"#delete columns --- this may or may NOT be needed.  As before - skip if you don't need it\n# You will encounter times where you will want to delete columns.  This is how you do that.\n# df = df.drop(['x5_latitude', 'x6_longitude', 'x1_transaction_date'], axis=1)\n# df","metadata":{"trusted":true},"execution_count":16,"outputs":[],"id":"2871e2ab-8677-43b4-bba1-36fe991438ab"},{"cell_type":"code","source":"'''\n# Split the data into test, train, validation sets... 60/20/20\nfrom sklearn.model_selection import train_test_split\n# This gives the 80/20 train test split\ndf_train_full, df_test = train_test_split(df, test_size=0.2, random_state=11)\n# This splits df_train_full again so it is 60/20/20\ndf_train, df_val = train_test_split(df_train_full, test_size=0.25, random_state=11)\nlen(df_train), len(df_val), len(df_test)\n# Replace nulls with 0's - these are pandas dataframes\ndf_train = df_train.fillna(0)\ndf_val = df_val.fillna(0)\ndf_test = df_test.fillna(0)\nlen(df_train),len(df_val),len(df_test)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"fe1b5783-3f32-4440-81b7-1ae401f4ef09"},{"cell_type":"code","source":"# Split the data into test, train, validation sets... 80/20\nfrom sklearn.model_selection import train_test_split\n# This gives the 80/20 train test split\ndf_train_full, df_test = train_test_split(df, test_size=0.2, random_state=11)\n\nlen(df_train_full), len(df_test)\n# Replace nulls with 0's - these are pandas dataframes\ndf_train_full = df_train_full.fillna(0)\n\ndf_test = df_test.fillna(0)\nlen(df_train_full),len(df_test)","metadata":{"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(3564, 891)"},"metadata":{}}],"id":"79babb7b-c583-4831-b555-54e68361b295"},{"cell_type":"code","source":"#Split the y out into train/test/splits... these are numpy ndarrays ... msrp is your target variables\n# Replace with your target variable!!!  \ny_train = (df_train_full.status).values\ny_test = (df_test.status).values\ndel df_train_full['status']\ndel df_test['status']\n","metadata":{"trusted":true},"execution_count":18,"outputs":[],"id":"033173c4-f018-4f63-b21b-f04209d392f7"},{"cell_type":"code","source":"len(y_train),len(y_test)","metadata":{"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(3564, 891)"},"metadata":{}}],"id":"cb9de144-603a-4450-892a-6d724878ed1a"},{"cell_type":"code","source":"# Convert these data frames into a LIST of DICTIONARIES (each element in the list is a dictionary (the record))\ndict_train = df_train_full.to_dict(orient='records')\ndict_test = df_test.to_dict(orient='records')","metadata":{"trusted":true},"execution_count":20,"outputs":[],"id":"65eccd7c-38b2-4c32-9408-1c3e4eeb78e9"},{"cell_type":"code","source":"# Convert the LIST OF DICTIONARIES into a Feature Matrix (does all of the encoding)\nfrom sklearn.feature_extraction import DictVectorizer\n \ndv = DictVectorizer(sparse=False)\n \nX_train = dv.fit_transform(dict_train)\nX_test = dv.transform(dict_test)\nfeatures = dv.get_feature_names_out()  #Features as they exist in the Vectorized Dictionary (this is an ndarray)","metadata":{"trusted":true},"execution_count":21,"outputs":[],"id":"8430e24e-0e56-4b06-8b2b-465762403e19"},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(891, 13)"},"metadata":{}}],"id":"e78f7c8e-e9f3-4a18-8d3c-b64873597b52"},{"cell_type":"code","source":"# Compare Algorithms\nfrom sklearn.metrics import roc_auc_score\nfrom time import time\nfrom sklearn.metrics import explained_variance_score,mean_absolute_error,r2_score\nfrom pandas import read_csv\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear')))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC(gamma='auto')))\n# evaluate each model in turn\nresults = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n    start = time()\n    kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n    model.fit(X_train, y_train)\n    train_time = time() - start\n    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    predict_time = time()-start \n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    #y_pred = model.predict_proba(X_train)[:, 1]\n    #auc = roc_auc_score(y_train, y_pred)\n    print(msg)\n    print(\"Score for each of the 10 K-fold tests: \",cv_results)\n    print(model)\n    print(\"\\tTraining time: %0.3fs\" % train_time)\n    print(\"\\tPrediction time: %0.3fs\" % predict_time)\n    #y_pred = model.predict(X_test)\n    #print(\"\\tExplained variance:\", explained_variance_score(y_test, y_pred))\n    print()\n    \n    \n    \n# boxplot algorithm comparison\nfig = pyplot.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\npyplot.boxplot(results)\nax.set_xticklabels(names)\npyplot.show()","metadata":{"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"LR: 0.786198 (0.012232)\nScore for each of the 10 K-fold tests:  [0.79271709 0.79271709 0.77871148 0.77030812 0.79494382 0.79213483\n 0.7752809  0.81179775 0.78089888 0.77247191]\nLogisticRegression(solver='liblinear')\n\tTraining time: 0.142s\n\tPrediction time: 1.422s\n\nLDA: 0.778351 (0.015439)\nScore for each of the 10 K-fold tests:  [0.78151261 0.77871148 0.76470588 0.74509804 0.80337079 0.79213483\n 0.77808989 0.78651685 0.76685393 0.78651685]\nLinearDiscriminantAnalysis()\n\tTraining time: 1.066s\n\tPrediction time: 1.349s\n\nKNN: 0.721115 (0.019672)\nScore for each of the 10 K-fold tests:  [0.70308123 0.71708683 0.72829132 0.68347339 0.71067416 0.75280899\n 0.74157303 0.73876404 0.70786517 0.72752809]\nKNeighborsClassifier()\n\tTraining time: 0.006s\n\tPrediction time: 0.314s\n\nCART: 0.711010 (0.017333)\nScore for each of the 10 K-fold tests:  [0.68907563 0.69747899 0.72268908 0.69467787 0.75280899 0.70505618\n 0.72191011 0.71067416 0.70505618 0.71067416]\nDecisionTreeClassifier()\n\tTraining time: 0.018s\n\tPrediction time: 0.193s\n\nNB: 0.757567 (0.018093)\nScore for each of the 10 K-fold tests:  [0.75070028 0.78431373 0.77591036 0.75070028 0.7752809  0.75842697\n 0.73033708 0.77247191 0.74719101 0.73033708]\nGaussianNB()\n\tTraining time: 0.002s\n\tPrediction time: 0.026s\n\nSVM: 0.723068 (0.014982)\nScore for each of the 10 K-fold tests:  [0.71708683 0.73109244 0.7254902  0.70308123 0.73033708 0.71067416\n 0.73595506 0.75561798 0.71067416 0.71067416]\nSVC(gamma='auto')\n\tTraining time: 0.923s\n\tPrediction time: 9.921s\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}],"id":"3c6ec7d7-b95f-496a-9b4b-82ddabb0b1ab"},{"cell_type":"markdown","source":"# Once you identify a single model or two - begin to investigate","metadata":{},"id":"a1e2fe12-ea3d-4e2d-965b-8e4d1c0dd661"},{"cell_type":"code","source":"# %%timeit -n 1\n# if you uncomment %%timeit it will not put lr into memory\n# Let's assume that the decision tree is the one we want to explore\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"DecisionTreeClassifier()"},"metadata":{}}],"id":"6d025def-452c-4def-807f-1da7523f0b60"},{"cell_type":"code","source":"dt.get_params()","metadata":{"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'ccp_alpha': 0.0,\n 'class_weight': None,\n 'criterion': 'gini',\n 'max_depth': None,\n 'max_features': None,\n 'max_leaf_nodes': None,\n 'min_impurity_decrease': 0.0,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'random_state': None,\n 'splitter': 'best'}"},"metadata":{}}],"id":"855abbd3-905c-4c96-93d1-c08ab4c495a9"},{"cell_type":"code","source":"type(X_train)\ntype(dv.get_feature_names_out())\ntype(dt.feature_importances_)","metadata":{"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}],"id":"4f6b5c2e-b5ea-41de-9943-da13c9b54e02"},{"cell_type":"code","source":"# These are the model properties.  You can call all of these\ndef get_properties(model):   \n  return [i for i in model.__dict__ if i.endswith('_')] \nget_properties(dt)","metadata":{"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"['n_features_in_',\n 'n_outputs_',\n 'classes_',\n 'n_classes_',\n 'max_features_',\n 'tree_']"},"metadata":{}}],"id":"b77b032f-0766-48e7-ac77-1ba688e3ffc2"},{"cell_type":"code","source":"from sklearn.tree import export_text \n \ntree_text = export_text(dt, feature_names=dv.feature_names_) \nprint(tree_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"ad10a5b7-e27c-4df3-8fce-118889329a33"},{"cell_type":"code","source":"feature_names=dv.feature_names_\n# Evaluate the coefficients to learn what the model thinks is important in the predictions.\nfor i,j in zip(feature_names, dt.feature_importances_): print('%.3f' % j, i)","metadata":{"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"0.100 age\n0.114 amount\n0.081 assets\n0.025 debt\n0.060 expenses\n0.039 home\n0.150 income\n0.048 job\n0.019 marital\n0.131 price\n0.085 records\n0.108 seniority\n0.041 time\n","output_type":"stream"}],"id":"a70eb705-485e-4e11-84f6-357949838a1a"},{"cell_type":"code","source":"from sklearn.metrics import f1_score\ny_pred = dt.predict_proba(X_test)[:, 1]\ny_pred = y_pred.astype('int')\nf1_score(y_test, y_pred, average=None)","metadata":{"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"array([0.       , 0.8031746, 0.       ])"},"metadata":{}}],"id":"82acda9d-b8a1-4517-8592-d7def874041f"},{"cell_type":"code","source":"y_pred.dtype","metadata":{"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"dtype('int64')"},"metadata":{}}],"id":"c982d83f-a5c9-4e71-a57f-1424de4f7640"},{"cell_type":"code","source":"# https://github.com/sepandhaghighi/pycm\n!pip install pycm\nfrom pycm import ConfusionMatrix\ncm = ConfusionMatrix(actual_vector=y_test,predict_vector=y_pred)\n# cm = ConfusionMatrix(y_actu, y_pred, classes=[1,0,4])\nprint(cm)","metadata":{"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pycm in /srv/conda/envs/notebook/lib/python3.7/site-packages (3.3)\nRequirement already satisfied: art>=1.8 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pycm) (5.3)\nRequirement already satisfied: numpy>=1.9.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pycm) (1.21.3)\nPredict   0         1         2         \nActual\n0         0         0         0         \n\n1         116       506       0         \n\n2         137       132       0         \n\n\n\n\n\nOverall Statistics : \n\n95% CI                                                            (0.53537,0.60043)\nACC Macro                                                         0.71193\nARI                                                               0.17162\nAUNP                                                              None\nAUNU                                                              None\nBangdiwala B                                                      0.64519\nBennett S                                                         0.35185\nCBA                                                               0.26437\nCSI                                                               None\nChi-Squared                                                       None\nChi-Squared DF                                                    4\nConditional Entropy                                               0.78637\nCramer V                                                          None\nCross Entropy                                                     0.33639\nF1 Macro                                                          0.26772\nF1 Micro                                                          0.5679\nFNR Macro                                                         None\nFNR Micro                                                         0.4321\nFPR Macro                                                         0.25822\nFPR Micro                                                         0.21605\nGwet AC1                                                          0.43989\nHamming Loss                                                      0.4321\nJoint Entropy                                                     1.66998\nKL Divergence                                                     None\nKappa                                                             0.13603\nKappa 95% CI                                                      (0.07099,0.20107)\nKappa No Prevalence                                               0.1358\nKappa Standard Error                                              0.03318\nKappa Unbiased                                                    0.05471\nKrippendorff Alpha                                                0.05524\nLambda A                                                          0.07807\nLambda B                                                          0.01976\nMutual Information                                                0.07441\nNIR                                                               0.69809\nOverall ACC                                                       0.5679\nOverall CEN                                                       0.37865\nOverall J                                                         (0.67109,0.2237)\nOverall MCC                                                       0.16432\nOverall MCEN                                                      0.45681\nOverall RACC                                                      0.49987\nOverall RACCU                                                     0.54289\nP-Value                                                           1.0\nPPV Macro                                                         None\nPPV Micro                                                         0.5679\nPearson C                                                         None\nPhi-Squared                                                       None\nRCI                                                               0.08421\nRR                                                                297.0\nReference Entropy                                                 0.88361\nResponse Entropy                                                  0.86078\nSOA1(Landis & Koch)                                               Slight\nSOA2(Fleiss)                                                      Poor\nSOA3(Altman)                                                      Poor\nSOA4(Cicchetti)                                                   Poor\nSOA5(Cramer)                                                      None\nSOA6(Matthews)                                                    Negligible\nScott PI                                                          0.05471\nStandard Error                                                    0.0166\nTNR Macro                                                         0.74178\nTNR Micro                                                         0.78395\nTPR Macro                                                         None\nTPR Micro                                                         0.5679\nZero-one Loss                                                     385\n\nClass Statistics :\n\nClasses                                                           0             1             2             \nACC(Accuracy)                                                     0.71605       0.72166       0.69809       \nAGF(Adjusted F-score)                                             0.0           0.65786       0.0           \nAGM(Adjusted geometric mean)                                      None          0.61251       0             \nAM(Difference between automatic and manual classification)        253           16            -269          \nAUC(Area under the ROC curve)                                     None          0.6614        0.5           \nAUCI(AUC value interpretation)                                    None          Fair          Poor          \nAUPR(Area under the PR curve)                                     None          0.8033        None          \nBCD(Bray-Curtis dissimilarity)                                    0.14198       0.00898       0.15095       \nBM(Informedness or bookmaker informedness)                        None          0.3228        0.0           \nCEN(Confusion entropy)                                            0.49751       0.3289        0.49988       \nDOR(Diagnostic odds ratio)                                        None          4.5273        None          \nDP(Discriminant power)                                            None          0.36158       None          \nDPI(Discriminant power interpretation)                            None          Poor          None          \nERR(Error rate)                                                   0.28395       0.27834       0.30191       \nF0.5(F0.5 score)                                                  0.0           0.7971        0.0           \nF1(F1 score - harmonic mean of precision and sensitivity)         0.0           0.80317       0.0           \nF2(F2 score)                                                      0.0           0.80934       0.0           \nFDR(False discovery rate)                                         1.0           0.2069        None          \nFN(False negative/miss/type 2 error)                              0             116           269           \nFNR(Miss rate or false negative rate)                             None          0.1865        1.0           \nFOR(False omission rate)                                          0.0           0.4585        0.30191       \nFP(False positive/type 1 error/false alarm)                       253           132           0             \nFPR(Fall-out or false positive rate)                              0.28395       0.49071       0.0           \nG(G-measure geometric mean of precision and sensitivity)          None          0.80324       None          \nGI(Gini index)                                                    None          0.3228        0.0           \nGM(G-mean geometric mean of specificity and sensitivity)          None          0.64367       0.0           \nIBA(Index of balanced accuracy)                                   None          0.54035       0.0           \nICSI(Individual classification success index)                     None          0.60661       None          \nIS(Information score)                                             None          0.18409       None          \nJ(Jaccard index)                                                  0.0           0.67109       0.0           \nLS(Lift score)                                                    None          1.1361        None          \nMCC(Matthews correlation coefficient)                             None          0.32865       None          \nMCCI(Matthews correlation coefficient interpretation)             None          Weak          None          \nMCEN(Modified confusion entropy)                                  0.49751       0.42779       0.49988       \nMK(Markedness)                                                    0.0           0.33461       None          \nN(Condition negative)                                             891           269           622           \nNLR(Negative likelihood ratio)                                    None          0.36618       1.0           \nNLRI(Negative likelihood ratio interpretation)                    None          Poor          Negligible    \nNPV(Negative predictive value)                                    1.0           0.5415        0.69809       \nOC(Overlap coefficient)                                           None          0.8135        None          \nOOC(Otsuka-Ochiai coefficient)                                    None          0.80324       None          \nOP(Optimized precision)                                           None          0.49169       -0.30191      \nP(Condition positive or support)                                  0             622           269           \nPLR(Positive likelihood ratio)                                    None          1.65782       None          \nPLRI(Positive likelihood ratio interpretation)                    None          Poor          None          \nPOP(Population)                                                   891           891           891           \nPPV(Precision or positive predictive value)                       0.0           0.7931        None          \nPRE(Prevalence)                                                   0.0           0.69809       0.30191       \nQ(Yule Q - coefficient of colligation)                            None          0.63816       None          \nQI(Yule Q interpretation)                                         None          Moderate      None          \nRACC(Random accuracy)                                             0.0           0.49987       0.0           \nRACCU(Random accuracy unbiased)                                   0.02016       0.49995       0.02279       \nTN(True negative/correct rejection)                               638           137           622           \nTNR(Specificity or true negative rate)                            0.71605       0.50929       1.0           \nTON(Test outcome negative)                                        638           253           891           \nTOP(Test outcome positive)                                        253           638           0             \nTP(True positive/hit)                                             0             506           0             \nTPR(Sensitivity, recall, hit rate, or true positive rate)         None          0.8135        0.0           \nY(Youden index)                                                   None          0.3228        0.0           \ndInd(Distance index)                                              None          0.52495       1.0           \nsInd(Similarity index)                                            None          0.6288        0.29289       \n\n","output_type":"stream"}],"id":"6fe5b7a3-0dd0-4848-94d4-75e42ce45518"},{"cell_type":"code","source":"type(y_test)","metadata":{"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}],"id":"cc78cca8-2d73-42ef-93e5-687f9f7299f3"},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix\n\ncnf_matrix = confusion_matrix(y_test, y_pred)\nprint(cnf_matrix)\n#[[1 1 3]\n# [3 2 2]\n# [1 3 1]]\n\nFP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \nFN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\nTP = np.diag(cnf_matrix)\nTN = cnf_matrix.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\n# print(FP)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\n# Sensitivity, hit rate, recall, or true positive rate\nTPR = TP/((TP+FN)+.01)\n# Specificity or true negative rate\nTNR = TN/((TN+FP)+.01)\n# Precision or positive predictive value\nPPV = TP/((TP+FP)+.01)\n# Negative predictive value\nNPV = TN/((TN+FN)+.01)\n# Fall out or false positive rate\nFPR = FP/((FP+TN)+.01)\n# False negative rate\nFNR = FN/((TP+FN)+.01)\n# False discovery rate\nFDR = FP/((TP+FP)+.01)\n# Overall accuracy\nACC = (TP+TN)/(TP+FP+FN+TN)\n","metadata":{"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"[[  0   0   0]\n [116 506   0]\n [137 132   0]]\n","output_type":"stream"}],"id":"b409e76c-e2b0-46b4-ba44-d6bbd475f2e6"},{"cell_type":"markdown","source":"The AUC-ROC curve is only for binary classification problems. But we can extend it to multiclass classification problems by using the One vs All technique(calculating auc-roc curve considering each label at a time and all the other can be grouped as one  label)","metadata":{},"id":"5c113874-33ea-46fa-ba6b-bb93d6741097"},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(\"For classification report:\")\nprint(classification_report(y_test , y_pred))\n\nfrom sklearn.metrics import confusion_matrix\nprint(\"For confusion matrix\")\nprint(confusion_matrix(y_test , y_pred))","metadata":{"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"For classification report:\n              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00         0\n         1.0       0.79      0.81      0.80       622\n         2.0       0.00      0.00      0.00       269\n\n    accuracy                           0.57       891\n   macro avg       0.26      0.27      0.27       891\nweighted avg       0.55      0.57      0.56       891\n\nFor confusion matrix\n[[  0   0   0]\n [116 506   0]\n [137 132   0]]\n","output_type":"stream"},{"name":"stderr","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"id":"9c4b11c1-bb50-4238-a247-95a9495e948c"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"78b66286-d96c-45c9-94f5-6edcbb7e4cd9"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"4147b82b-70c5-413d-9473-b5ddc453450a"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"5349237f-855b-4790-b698-365cfd45cdaf"},{"cell_type":"code","source":"pred_y = dt.predict(X_test)\nprint(\"The first 10 prediction {}\".format(pred_y[:10].round(0)))\nprint(\"The real first 10 labels {}\".format(y_test[:10]))\n\n","metadata":{"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"The first 10 prediction [1 2 1 1 1 1 1 1 2 1]\nThe real first 10 labels [1 2 1 1 2 1 1 2 1 1]\n","output_type":"stream"}],"id":"4a0ca23f-81cd-4f0a-b815-66ab6d56dafd"},{"cell_type":"code","source":"type(df_train_full.head(1))","metadata":{"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"pandas.core.frame.DataFrame"},"metadata":{}}],"id":"6458b9b4-53f5-4325-8cc8-e316fb20eae0"},{"cell_type":"code","source":"# Use double brackets around the iloc to force it to return a pandas dataframe and not a series\n# Then you can convert any record into a dictionary\ndf_train_full.iloc[[21]]","metadata":{"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"      seniority  home  time  age  marital  records  job  expenses  income  \\\n3576         17     1    60   52        2        1    1        65   200.0   \n\n      assets  debt  amount  price  \n3576     0.0   0.0    1400   1407  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seniority</th>\n      <th>home</th>\n      <th>time</th>\n      <th>age</th>\n      <th>marital</th>\n      <th>records</th>\n      <th>job</th>\n      <th>expenses</th>\n      <th>income</th>\n      <th>assets</th>\n      <th>debt</th>\n      <th>amount</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3576</th>\n      <td>17</td>\n      <td>1</td>\n      <td>60</td>\n      <td>52</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>65</td>\n      <td>200.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1400</td>\n      <td>1407</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"id":"6cfd0fbc-b397-4c86-9be0-4d5b105c7a04"},{"cell_type":"code","source":"# How to convert any pandas row into a dictionary... needed for predictions\ndf_train_full.iloc[[213]].to_dict('records')[0]","metadata":{"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"{'seniority': 7,\n 'home': 3,\n 'time': 36,\n 'age': 24,\n 'marital': 1,\n 'records': 1,\n 'job': 3,\n 'expenses': 35,\n 'income': 131.0,\n 'assets': 7500.0,\n 'debt': 0.0,\n 'amount': 1350,\n 'price': 1406}"},"metadata":{}}],"id":"0b519a52-11f8-4d03-9cb2-fee16a79acbf"},{"cell_type":"code","source":"# How to convert any pandas row into a dictionary... needed for predictions\ndf_train_full.head(21).to_dict('records')[0]","metadata":{"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"{'seniority': 6,\n 'home': 6,\n 'time': 30,\n 'age': 22,\n 'marital': 1,\n 'records': 1,\n 'job': 1,\n 'expenses': 35,\n 'income': 73.0,\n 'assets': 0.0,\n 'debt': 0.0,\n 'amount': 1086,\n 'price': 1086}"},"metadata":{}}],"id":"78bc6352-6bab-4356-9e6e-07c1a977a06f"},{"cell_type":"code","source":"#car = df_train.head(1).to_dict('records')[0]\nitem = df_train_full.iloc[[213]].to_dict('records')[0]\nactual = y_train[[213]]","metadata":{"trusted":true},"execution_count":78,"outputs":[],"id":"8f58aa87-c643-4a94-b0ab-c0582ee4e18d"},{"cell_type":"code","source":"# The item to be predicted is passed in.  \ndef model_prediction(item, dv, model):\n    X = dv.transform([item])\n    y_pred = model.predict(X)\n    return y_pred[0]","metadata":{"trusted":true},"execution_count":82,"outputs":[],"id":"0b8da488-76d2-4c2e-88b4-59f0390517e4"},{"cell_type":"code","source":"model_prediction(item,dv,dt)","metadata":{"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}],"id":"25ee6832-7b4b-40f1-9f02-46f611d87968"},{"cell_type":"code","source":"actual","metadata":{"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"array([1])"},"metadata":{}}],"id":"a2dbd283-4485-44e5-aa81-fdc0c0ebb813"},{"cell_type":"code","source":"dt.get_params()","metadata":{"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"{'ccp_alpha': 0.0,\n 'class_weight': None,\n 'criterion': 'gini',\n 'max_depth': None,\n 'max_features': None,\n 'max_leaf_nodes': None,\n 'min_impurity_decrease': 0.0,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'random_state': None,\n 'splitter': 'best'}"},"metadata":{}}],"id":"940c8c4e-d164-4da0-8287-630f7306b78a"},{"cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{},"id":"a3376d80-ebf1-4a3b-9570-f01c2bb16cc8"},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nparams = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\ngrid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=3)\ngrid_search_cv.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 294 candidates, totalling 882 fits\n","output_type":"stream"},{"name":"stderr","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n  UserWarning,\n","output_type":"stream"},{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n             param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n                                            31, ...],\n                         'min_samples_split': [2, 3, 4]},\n             verbose=1)"},"metadata":{}}],"id":"976b78b1-f559-48bb-b0fc-2ace1b82088f"},{"cell_type":"code","source":"grid_search_cv.best_estimator_    # this will output the best values for the hyperparameters","metadata":{"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"DecisionTreeClassifier(max_leaf_nodes=23, random_state=42)"},"metadata":{}}],"id":"633aa3d9-1e39-4c1c-b889-1684f99e9825"},{"cell_type":"code","source":"from sklearn.tree import export_graphviz\nexport_graphviz( \n grid_search_cv.best_estimator_,\n out_file=('tree.dot'),\n feature_names=None,\n class_names=None,\n filled=True,\n)","metadata":{"trusted":true},"execution_count":102,"outputs":[],"id":"bd4ea648-fadd-4604-92e0-c5d39657eb9c"},{"cell_type":"code","source":"!pip install pydot\nimport pydot\n\n(graph,) = pydot.graph_from_dot_file('tree.dot')\ngraph.write_png('tree.png')","metadata":{"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"Collecting pydot\n  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\nRequirement already satisfied: pyparsing>=2.1.4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pydot) (2.4.7)\nInstalling collected packages: pydot\nSuccessfully installed pydot-1.4.2\n","output_type":"stream"}],"id":"4b1d5356-f985-4b12-8982-b8107596c1b7"},{"cell_type":"code","source":"# You can change the params by editing the output of this and repeating the above steps.\ndt.get_params()","metadata":{"trusted":true},"execution_count":107,"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"{'ccp_alpha': 0.0,\n 'class_weight': None,\n 'criterion': 'gini',\n 'max_depth': None,\n 'max_features': None,\n 'max_leaf_nodes': None,\n 'min_impurity_decrease': 0.0,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'random_state': None,\n 'splitter': 'best'}"},"metadata":{}}],"id":"44b575ad-7e8b-4486-98f3-4c70510aa742"},{"cell_type":"code","source":"#Many parameters will take a very long time to load\nparam = { 'max_depth': [2,3,5,20,40], \n         'max_leaf_nodes': [2,20,200]}","metadata":{"trusted":true},"execution_count":108,"outputs":[],"id":"f7881392-37cd-405b-8f80-3282f763a90e"},{"cell_type":"code","source":"metrics.SCORERS.keys()","metadata":{"trusted":true},"execution_count":111,"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"},"metadata":{}}],"id":"c46cb5ba-a070-47f1-9e17-7e61b44d1054"},{"cell_type":"code","source":"from sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import GridSearchCV\ncv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n# define search\nsearch = GridSearchCV(dt, param, scoring='accuracy', n_jobs=-1, cv=cv)\n# execute search\nresult = search.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":113,"outputs":[],"id":"91bd0b8f-8fd4-4e9a-9823-d6f531790d63"},{"cell_type":"code","source":"# summarize result\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)","metadata":{"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"Best Score: 0.7789076679360885\nBest Hyperparameters: {'max_depth': 20, 'max_leaf_nodes': 20}\n","output_type":"stream"}],"id":"46caaf03-88e3-4434-9ac2-0ce804f8e020"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"303e98c0-40ed-42c3-9c74-df96f0747223"}]}